\documentclass[
]{article}

\setlength\parindent{0pt}

\usepackage{amsmath}
\usepackage{amssymb}

\usepackage[normalem]{ulem}

\usepackage{cancel}

\usepackage{ifthen}
\usepackage{trimspaces}

\usepackage{graphicx}
\usepackage{xesearch}
\usepackage[dvipsnames]{xcolor}

\usepackage{enumitem}
\setlistdepth{9}

\setlist[itemize,1]{label=\textbullet}
\setlist[itemize,2]{label=\textbullet}
\setlist[itemize,3]{label=\textbullet}
\setlist[itemize,4]{label=\textbullet}
\setlist[itemize,5]{label=\textbullet}
\setlist[itemize,6]{label=\textbullet}
\setlist[itemize,7]{label=\textbullet}
\setlist[itemize,8]{label=\textbullet}
\setlist[itemize,9]{label=\textbullet}

\renewlist{itemize}{itemize}{9}

\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother


\UndoBoundary{[, ], \_}
\SearchList{startbrac}{}{*[?}
\SearchList{endbrac}{}{*]?}
\SearchList{kbtag}{\color{ForestGreen}{\href{http://taproot.shabang.cf/relay?request=#1}{\tiny\textulf{[[}\textbf{#1}\textulf{]]}}}\color{black}}{*KB?}



% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\graphicspath{ {./} }

\usepackage{titlesec}
\usepackage{titling}
\usepackage{makecell}
\usepackage{bookmark}

\usepackage{float}
\let\origfigure\figure
\let\endorigfigure\endfigure
\renewenvironment{figure}[1][2] {
    \expandafter\origfigure\expandafter[H]
} {
    \endorigfigure
}

\usepackage{mathspec}
%\setmainfont[
%   ItalicFont     = HelveticaNeue-Italic,
%   BoldFont       = HelveticaNeue-Bold,
%   BoldItalicFont = HelveticaNeue-BoldItalic]{HelveticaNeue}
%\newfontfamily\NHLight[
%   ItalicFont     = HelveticaNeue-LightItalic,
%   BoldFont       = HelveticaNeue-UltraLight,
%   BoldItalicFont = HelveticaNeue-UltraLightItalic]{HelveticaNeue-Light}
\setmainfont[
   ItalicFont     = Iosevka-Aile-Italic,
   BoldFont       = Iosevka-Aile-Bold,
   BoldItalicFont = Iosevka-Aile-Bold-Italic]{Iosevka}
\newfontfamily\NHLight[
   ItalicFont     = Iosevka-Aile-Light-Italic,
   BoldFont       = Iosevka-Aile-Light,
   BoldItalicFont = Iosevka-Aile-Light-Italic]{Iosevka-Light}

\newcommand\textrmlf[1]{{\NHLight#1}}
\newcommand\textitlf[1]{{\NHLight\itshape#1}}
\let\textbflf\textrm
\newcommand\textulf[1]{{\NHLight\bfseries#1}}
\newcommand\textuitlf[1]{{\NHLight\bfseries\itshape#1}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}



\usepackage[margin=1in]{geometry}

\usepackage{fancyhdr}
\usepackage{hyperref}

\usepackage{longtable,booktabs}
\usepackage{caption}
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}


\newcommand{\thecourse}{ ML301 }
\newcommand{\thelesson}{ Weight Agnostic Neural Networks }

\title{\textbf{\thecourse}\thelesson}

\pagestyle{fancy}

\fancyfoot{}

\makeatletter
\trim@spaces@in \thecourse
\trim@spaces@in \thelesson
\makeatother
\lhead{\textbf{\thecourse} \thelesson}
%\rhead{\textrmlf{Compiled} \today \textrmlf{\ ({\#}6233)}}    % original
%\rhead{\textrmlf{Compiled }\#6233\textrmlf{ on} \today }      % old date
\rhead{\textrmlf{Compiled }\#6233\textrmlf{ on} \today}       % new date
\lfoot{Huxley \(\cdot\) \textbf{2020-2021}}
\rfoot{\textrmlf{Page} \thepage}


\titleformat{\section}
{\Large}
{\textrmlf{\thesection} {|}}
{0.3em}
{\textbf}


\titleformat{\subsection}
{\large}
{\textrmlf{\thesubsection} {|}}
{0.2em}
{\textbf}

\titleformat{\subsubsection}
{\large}
{\textrmlf{\thesubsubsection} {|}}
{0.1em}
{\textbf}

\setlength{\parskip}{0.45em}

\newcounter{definitionct}
\newcommand{\definition}[3][]{
    \stepcounter{definitionct}
    \begin{center}
        Definition \arabic{definitionct} \(\cdot\) [ \textbf{#2} \textrmlf{#3} ]
        \ifthenelse{ \equal{#1}{} }
            {}
            {\\ \textrmlf{#1}}
    \end{center}
}

\begin{document}

% DID YOU SET SPELL????
\textbf{Source}:\thinspace 
{\href{http://taproot.shabang.cf/relay?request=}{\tiny\textulf{[[}\textbf{}\textulf{]]}}}\thinspace

\#ref \#ret

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{weight-agnostic-neural-networks}{%
\section{Weight Agnostic Neural
Networks}\label{weight-agnostic-neural-networks}}

\emph{Or WANNN, for short.}

My personal note's on
\href{https://towardsdatascience.com/weight-agnostic-neural-networks-fce8120ee829}{this
article}, and also
\href{https://ai.googleblog.com/2019/08/exploring-weight-agnostic-neural.html}{this
article}.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Animals can perform tasks when they are born without prior experience to
the world. If the brain is pre-wired, then learning new from experience
would cause a loss of the old skill. What gives?

WANNs can perform tasks regardless of the weights in its connections by
operating off of a pre-made structure.

Also, finding structures with inductive bias is hard and slow!

\hypertarget{neat}{%
\subsection{NEAT}\label{neat}}

\emph{NeuroEvolution of Augmented Topologies}

Genetic algorithm in which mutations are done by changing the
\textbf{structure} of the network.

\hypertarget{back-to-wann}{%
\subsection{Back to WANN}\label{back-to-wann}}

Can generalize the network to work with a range of weight values?

Instead of changing connection weights, they

\begin{itemize}
\tightlist
\item
  add connections,
\item
  add weight,
\item
  change activation functions.
\end{itemize}

\begin{quote}
Networks in which the structure enables the task to be completed, not
the weights, can be developed.
\end{quote}

\hypertarget{finding-wanns}{%
\subsubsection{Finding WANNs}\label{finding-wanns}}

Start with a small amount of network architectures then use NEAT on
them. With this system of growth and training, easier and more efficient
to optimize models across a wide range of input values.

Also optimizes for less complexity in the network.

Is general, but not as good at the individual scenarios as normal
networks.

\textbf{Proposed: WANN as starting point, then run normal training on
the network}

Also allows for much easier training as the structure generally has a
lot less nodes as it is specialized for a certain task.

Analogous to how animals learn.

Can also copy WANN network, and individually train, then use them in
collections for different input values?

\hypertarget{so}{%
\subsection{So?}\label{so}}

WANNs make models more interpretable, as their solutions or logic is
encoded directly into their structure.

More general, and deals better with varying inputs.

Also allows us to encode `intellegence' from the creation of of the
network

Can be used to find `building blocks,' sort of like automating the
finding of revolutionary structures like CNNs.

\end{document}
